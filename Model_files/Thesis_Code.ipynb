{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1d4bf8c0-69e9-4874-9b03-ca2d043fafaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Robust Glaucoma Detection System...\n",
      "All outputs will be saved to: /Users/adyasha/Downloads/thesis_data/outputs\n",
      "Precomputing features for 4319 images...\n",
      "Feature computation completed in 9.5 seconds\n",
      "Precomputing features for 98 images...\n",
      "Feature computation completed in 0.0 seconds\n",
      "Precomputing features for 335 images...\n",
      "Feature computation completed in 0.1 seconds\n",
      "Class weights: {0: 1.2869487485101312, 1: 0.8176826959485044}\n",
      "\n",
      "=== Phase 1: Training head ===\n",
      "Epoch 1/15\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 336ms/step - accuracy: 0.6323 - auc: 0.6839 - loss: 0.9053 - val_accuracy: 0.7449 - val_auc: 0.7755 - val_loss: 0.8244 - learning_rate: 3.3333e-05\n",
      "Epoch 2/15\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 337ms/step - accuracy: 0.7404 - auc: 0.8172 - loss: 0.7483 - val_accuracy: 0.7347 - val_auc: 0.8609 - val_loss: 0.7088 - learning_rate: 6.6667e-05\n",
      "Epoch 3/15\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 343ms/step - accuracy: 0.7925 - auc: 0.8742 - loss: 0.6617 - val_accuracy: 0.8061 - val_auc: 0.8876 - val_loss: 0.6421 - learning_rate: 1.0000e-04\n",
      "Epoch 4/15\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 347ms/step - accuracy: 0.8252 - auc: 0.9040 - loss: 0.6000 - val_accuracy: 0.8469 - val_auc: 0.9043 - val_loss: 0.6021 - learning_rate: 1.0000e-04\n",
      "Epoch 5/15\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 346ms/step - accuracy: 0.8365 - auc: 0.9156 - loss: 0.5695 - val_accuracy: 0.7959 - val_auc: 0.9074 - val_loss: 0.5968 - learning_rate: 1.0000e-04\n",
      "Epoch 6/15\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 348ms/step - accuracy: 0.8370 - auc: 0.9185 - loss: 0.5555 - val_accuracy: 0.8469 - val_auc: 0.9089 - val_loss: 0.5792 - learning_rate: 1.0000e-04\n",
      "Epoch 7/15\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 350ms/step - accuracy: 0.8502 - auc: 0.9255 - loss: 0.5344 - val_accuracy: 0.7857 - val_auc: 0.9034 - val_loss: 0.6006 - learning_rate: 1.0000e-04\n",
      "Epoch 8/15\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346ms/step - accuracy: 0.8595 - auc: 0.9331 - loss: 0.5137\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 353ms/step - accuracy: 0.8590 - auc: 0.9326 - loss: 0.5130 - val_accuracy: 0.8061 - val_auc: 0.9066 - val_loss: 0.5827 - learning_rate: 5.0000e-05\n",
      "Epoch 9/15\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 363ms/step - accuracy: 0.8567 - auc: 0.9359 - loss: 0.4996 - val_accuracy: 0.8571 - val_auc: 0.9110 - val_loss: 0.5561 - learning_rate: 1.0000e-04\n",
      "Epoch 10/15\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 355ms/step - accuracy: 0.8662 - auc: 0.9406 - loss: 0.4841 - val_accuracy: 0.8469 - val_auc: 0.9118 - val_loss: 0.5524 - learning_rate: 1.0000e-04\n",
      "Epoch 11/15\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 358ms/step - accuracy: 0.8687 - auc: 0.9399 - loss: 0.4817 - val_accuracy: 0.8571 - val_auc: 0.9097 - val_loss: 0.5464 - learning_rate: 1.0000e-04\n",
      "Epoch 12/15\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 356ms/step - accuracy: 0.8680 - auc: 0.9436 - loss: 0.4679 - val_accuracy: 0.8469 - val_auc: 0.9125 - val_loss: 0.5359 - learning_rate: 1.0000e-04\n",
      "Epoch 13/15\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 356ms/step - accuracy: 0.8747 - auc: 0.9452 - loss: 0.4600 - val_accuracy: 0.8571 - val_auc: 0.9112 - val_loss: 0.5369 - learning_rate: 1.0000e-04\n",
      "Epoch 14/15\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 362ms/step - accuracy: 0.8787 - auc: 0.9476 - loss: 0.4507 - val_accuracy: 0.8265 - val_auc: 0.9135 - val_loss: 0.5326 - learning_rate: 1.0000e-04\n",
      "Epoch 15/15\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 366ms/step - accuracy: 0.8731 - auc: 0.9501 - loss: 0.4401 - val_accuracy: 0.8469 - val_auc: 0.9045 - val_loss: 0.5372 - learning_rate: 1.0000e-04\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "\n",
      "=== Phase 2: Fine-tuning ===\n",
      "Number of trainable layers: 55\n",
      "Epoch 16/25\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 528ms/step - accuracy: 0.7539 - auc: 0.8589 - loss: 0.6519 - val_accuracy: 0.7245 - val_auc: 0.9003 - val_loss: 0.7014 - learning_rate: 1.0000e-05\n",
      "Epoch 17/25\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 518ms/step - accuracy: 0.8472 - auc: 0.9260 - loss: 0.5005 - val_accuracy: 0.7857 - val_auc: 0.9112 - val_loss: 0.6606 - learning_rate: 1.0000e-05\n",
      "Epoch 18/25\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 517ms/step - accuracy: 0.8787 - auc: 0.9483 - loss: 0.4458 - val_accuracy: 0.7755 - val_auc: 0.9152 - val_loss: 0.6452 - learning_rate: 1.0000e-05\n",
      "Epoch 19/25\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 518ms/step - accuracy: 0.8872 - auc: 0.9557 - loss: 0.4235 - val_accuracy: 0.8163 - val_auc: 0.9253 - val_loss: 0.5832 - learning_rate: 1.0000e-05\n",
      "Epoch 20/25\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 516ms/step - accuracy: 0.9025 - auc: 0.9677 - loss: 0.3846 - val_accuracy: 0.8163 - val_auc: 0.9209 - val_loss: 0.5845 - learning_rate: 1.0000e-05\n",
      "Epoch 21/25\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 519ms/step - accuracy: 0.9034 - auc: 0.9680 - loss: 0.3830 - val_accuracy: 0.8061 - val_auc: 0.9301 - val_loss: 0.6037 - learning_rate: 1.0000e-05\n",
      "Epoch 22/25\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 520ms/step - accuracy: 0.9176 - auc: 0.9756 - loss: 0.3540 - val_accuracy: 0.8673 - val_auc: 0.9322 - val_loss: 0.5497 - learning_rate: 1.0000e-05\n",
      "Epoch 23/25\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 524ms/step - accuracy: 0.9252 - auc: 0.9793 - loss: 0.3385 - val_accuracy: 0.8469 - val_auc: 0.9354 - val_loss: 0.5413 - learning_rate: 1.0000e-05\n",
      "Epoch 24/25\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 517ms/step - accuracy: 0.9298 - auc: 0.9792 - loss: 0.3360 - val_accuracy: 0.8469 - val_auc: 0.9423 - val_loss: 0.5103 - learning_rate: 1.0000e-05\n",
      "Epoch 25/25\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 521ms/step - accuracy: 0.9342 - auc: 0.9837 - loss: 0.3154 - val_accuracy: 0.8878 - val_auc: 0.9539 - val_loss: 0.4378 - learning_rate: 1.0000e-05\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "Precomputing features for 4319 images...\n",
      "Feature computation completed in 1.9 seconds\n",
      "Precomputing features for 98 images...\n",
      "Feature computation completed in 0.0 seconds\n",
      "Precomputing features for 335 images...\n",
      "Feature computation completed in 0.1 seconds\n",
      "\n",
      "Evaluating model...\n",
      "Test set class distribution: {'Glaucoma': 156, 'Normal': 179}\n",
      "\n",
      "Test Results:\n",
      "Loss: 0.3775\n",
      "Accuracy: 0.9104\n",
      "AUC: 0.9782\n",
      "Unique values in y_true: [0 1]\n",
      "Labels are 0 and 1, no adjustment needed\n",
      "Adjusted unique values: [0 1]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.96      0.85      0.90       156\n",
      "    Glaucoma       0.88      0.97      0.92       179\n",
      "\n",
      "    accuracy                           0.91       335\n",
      "   macro avg       0.92      0.91      0.91       335\n",
      "weighted avg       0.91      0.91      0.91       335\n",
      "\n",
      "\n",
      "Analyzing feature importance...\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 313ms/step\n",
      "Baseline AUC: 0.9780\n",
      "Processing feature 1/14: vertical_cdr\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 302ms/step\n",
      "  Feature importance: -0.0004\n",
      "Processing feature 2/14: horizontal_cdr\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 300ms/step\n",
      "  Feature importance: 0.0001\n",
      "Processing feature 3/14: area_cdr\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 298ms/step\n",
      "  Feature importance: 0.0000\n",
      "Processing feature 4/14: rim_ratio\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 311ms/step\n",
      "  Feature importance: -0.0002\n",
      "Processing feature 5/14: inferior_rim\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 308ms/step\n",
      "  Feature importance: -0.0000\n",
      "Processing feature 6/14: superior_rim\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 303ms/step\n",
      "  Feature importance: -0.0000\n",
      "Processing feature 7/14: nasal_rim\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 299ms/step\n",
      "  Feature importance: 0.0000\n",
      "Processing feature 8/14: temporal_rim\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 299ms/step\n",
      "  Feature importance: 0.0000\n",
      "Processing feature 9/14: mean_pallor\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 317ms/step\n",
      "  Feature importance: -0.0006\n",
      "Processing feature 10/14: max_pallor\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 300ms/step\n",
      "  Feature importance: -0.0000\n",
      "Processing feature 11/14: pallor_asymmetry\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 301ms/step\n",
      "  Feature importance: 0.0002\n",
      "Processing feature 12/14: vessel_density\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 298ms/step\n",
      "  Feature importance: -0.0001\n",
      "Processing feature 13/14: vessel_tortuosity\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 300ms/step\n",
      "  Feature importance: -0.0000\n",
      "Processing feature 14/14: istn_compliance\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 316ms/step\n",
      "  Feature importance: 0.0000\n",
      "\n",
      "Execution completed successfully in 25.22 minutes!\n",
      "All outputs saved to: /Users/adyasha/Downloads/thesis_data/outputs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import RobustScaler, LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Concatenate, Dropout, RandomFlip, RandomRotation, RandomZoom, RandomContrast\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow as tf\n",
    "from typing import Tuple, Dict, List\n",
    "import pandas as pd\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Enhanced configuration\n",
    "class Config:\n",
    "    SEED = 42\n",
    "    IMAGE_SIZE = (224, 224)\n",
    "    BATCH_SIZE = 32\n",
    "    INITIAL_EPOCHS = 15\n",
    "    FINE_TUNE_EPOCHS = 10\n",
    "    DATA_DIR = '/Users/adyasha/Downloads/thesis_data/'\n",
    "    OUTPUT_DIR = os.path.join(DATA_DIR, 'outputs')  # New output directory\n",
    "    CLINICAL_FEATURES = [\n",
    "        'vertical_cdr', 'horizontal_cdr', 'area_cdr', 'rim_ratio',\n",
    "        'inferior_rim', 'superior_rim', 'nasal_rim', 'temporal_rim',\n",
    "        'mean_pallor', 'max_pallor', 'pallor_asymmetry',\n",
    "        'vessel_density', 'vessel_tortuosity', 'istn_compliance'\n",
    "    ]\n",
    "    AUGMENTATION_PARAMS = {\n",
    "        'flip': True,\n",
    "        'rotation': 0.1,\n",
    "        'zoom': 0.1,\n",
    "        'contrast': (0.9, 1.1),\n",
    "        'brightness': 0.1\n",
    "    }\n",
    "    REGULARIZATION_L2 = 0.001\n",
    "    DROPOUT_RATE = 0.5\n",
    "    FINE_TUNE_AT = 100\n",
    "    FEATURE_LENGTH = len(CLINICAL_FEATURES)  # Ensure consistent feature length\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(Config.OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(Config.SEED)\n",
    "tf.random.set_seed(Config.SEED)\n",
    "\n",
    "# Enhanced Optic Disc Analyzer\n",
    "class OpticDiscAnalyzer:\n",
    "    \"\"\"Optimized optic disc feature extraction with caching and shape consistency\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.cache = {}\n",
    "        \n",
    "    def analyze_image(self, img: np.ndarray) -> Dict[str, float]:\n",
    "        \"\"\"Consistent feature extraction\"\"\"\n",
    "        if img is None or img.size == 0:\n",
    "            return {k: 0.0 for k in Config.CLINICAL_FEATURES}\n",
    "        \n",
    "        # Use image hash for caching\n",
    "        img_hash = hash(img.tobytes())\n",
    "        if img_hash in self.cache:\n",
    "            return self.cache[img_hash]\n",
    "        \n",
    "        # Preprocess image\n",
    "        if len(img.shape) == 2:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "        img = cv2.resize(img, Config.IMAGE_SIZE)\n",
    "        \n",
    "        # Simulated feature extraction - ensure consistent output\n",
    "        features = {\n",
    "            'vertical_cdr': float(np.random.uniform(0.3, 0.8)),\n",
    "            'horizontal_cdr': float(np.random.uniform(0.3, 0.8)),\n",
    "            'area_cdr': float(np.random.uniform(0.3, 0.8)),\n",
    "            'rim_ratio': float(np.random.uniform(0.1, 0.5)),\n",
    "            'inferior_rim': float(np.random.uniform(0.05, 0.2)),\n",
    "            'superior_rim': float(np.random.uniform(0.05, 0.2)),\n",
    "            'nasal_rim': float(np.random.uniform(0.05, 0.2)),\n",
    "            'temporal_rim': float(np.random.uniform(0.05, 0.2)),\n",
    "            'mean_pallor': float(np.random.uniform(100, 200)),\n",
    "            'max_pallor': float(np.random.uniform(150, 250)),\n",
    "            'pallor_asymmetry': float(np.random.uniform(0.1, 0.3)),\n",
    "            'vessel_density': float(np.random.uniform(0.1, 0.4)),\n",
    "            'vessel_tortuosity': float(np.random.uniform(1.0, 1.5)),\n",
    "            'istn_compliance': float(np.random.choice([0, 1]))\n",
    "        }\n",
    "        \n",
    "        self.cache[img_hash] = features\n",
    "        return features\n",
    "\n",
    "# Robust Data Generator\n",
    "class GlaucomaDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, directory: str, analyzer: OpticDiscAnalyzer, \n",
    "                 shuffle: bool = True, augment: bool = False):\n",
    "        self.directory = directory\n",
    "        self.analyzer = analyzer\n",
    "        self.shuffle = shuffle\n",
    "        self.augment = augment\n",
    "        self.class_folders = sorted(os.listdir(directory))\n",
    "        self.class_encoder = LabelEncoder()\n",
    "        self.file_paths = self._get_file_paths()\n",
    "        self.scaler = RobustScaler()\n",
    "        self.indexes = np.arange(len(self.file_paths))\n",
    "        self.on_epoch_end()\n",
    "        self.precomputed_features = self._precompute_features_parallel()\n",
    "    \n",
    "    def _get_file_paths(self) -> List[Tuple[str, int]]:\n",
    "        paths = []\n",
    "        for class_name in self.class_folders:\n",
    "            class_dir = os.path.join(self.directory, class_name)\n",
    "            if not os.path.isdir(class_dir):\n",
    "                continue\n",
    "                \n",
    "            for filename in os.listdir(class_dir):\n",
    "                if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    file_path = os.path.join(class_dir, filename)\n",
    "                    if os.path.isfile(file_path):\n",
    "                        paths.append((file_path, class_name))\n",
    "        \n",
    "        # Encode class labels\n",
    "        all_labels = [label for _, label in paths]\n",
    "        if not all_labels:\n",
    "            raise ValueError(f\"No valid images found in directory: {self.directory}\")\n",
    "            \n",
    "        self.class_encoder.fit(all_labels)\n",
    "        self.classes = self.class_encoder.classes_\n",
    "        \n",
    "        # Convert to numerical labels\n",
    "        paths = [(path, self.class_encoder.transform([label])[0]) for path, label in paths]\n",
    "        return paths\n",
    "    \n",
    "    def _process_image(self, file_path: str) -> np.ndarray:\n",
    "        \"\"\"Process a single image file with error handling and shape validation\"\"\"\n",
    "        try:\n",
    "            img = cv2.imread(file_path)\n",
    "            if img is None:\n",
    "                print(f\"Warning: Could not load image {file_path}. Using zeros.\")\n",
    "                return np.zeros(Config.FEATURE_LENGTH, dtype=np.float32)\n",
    "                \n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            features_dict = self.analyzer.analyze_image(img)\n",
    "            \n",
    "            # Ensure consistent feature order and length\n",
    "            features = np.array([features_dict[k] for k in Config.CLINICAL_FEATURES], dtype=np.float32)\n",
    "            \n",
    "            if features.shape != (Config.FEATURE_LENGTH,):\n",
    "                print(f\"Warning: Invalid feature shape {features.shape} for {file_path}. Using zeros.\")\n",
    "                return np.zeros(Config.FEATURE_LENGTH, dtype=np.float32)\n",
    "                \n",
    "            return features\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {str(e)}\")\n",
    "            return np.zeros(Config.FEATURE_LENGTH, dtype=np.float32)\n",
    "    \n",
    "    def _precompute_features_parallel(self) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"Precompute features using parallel processing with shape validation\"\"\"\n",
    "        features = {}\n",
    "        print(f\"Precomputing features for {len(self.file_paths)} images...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Use ThreadPoolExecutor for parallel processing\n",
    "        with ThreadPoolExecutor(max_workers=min(8, os.cpu_count())) as executor:\n",
    "            futures = {}\n",
    "            for file_path, _ in self.file_paths:\n",
    "                futures[file_path] = executor.submit(self._process_image, file_path)\n",
    "            \n",
    "            for file_path, future in futures.items():\n",
    "                features[file_path] = future.result()\n",
    "        \n",
    "        # Validate all features have consistent shape\n",
    "        all_features = np.array(list(features.values()))\n",
    "        if all_features.ndim != 2 or all_features.shape[1] != Config.FEATURE_LENGTH:\n",
    "            raise ValueError(f\"Feature array has invalid shape {all_features.shape}. Expected (n, {Config.FEATURE_LENGTH})\")\n",
    "        \n",
    "        self.scaler.fit(all_features)\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"Feature computation completed in {elapsed:.1f} seconds\")\n",
    "        return features\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return int(np.ceil(len(self.file_paths) / Config.BATCH_SIZE))\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Tuple[Tuple[np.ndarray, np.ndarray], np.ndarray]:\n",
    "        batch_indices = self.indexes[idx*Config.BATCH_SIZE:(idx+1)*Config.BATCH_SIZE]\n",
    "        batch_paths = [self.file_paths[i] for i in batch_indices]\n",
    "        \n",
    "        images = []\n",
    "        clinical_features = []\n",
    "        diagnosis_labels = []\n",
    "        \n",
    "        for file_path, label in batch_paths:\n",
    "            img = self._load_and_preprocess(file_path)\n",
    "            images.append(img)\n",
    "            clinical_features.append(self.precomputed_features[file_path])\n",
    "            diagnosis_labels.append(label)\n",
    "        \n",
    "        # Convert to arrays with consistent shapes\n",
    "        images = np.stack(images, axis=0)\n",
    "        clinical_features = np.stack(clinical_features, axis=0)\n",
    "        clinical_features = self.scaler.transform(clinical_features)\n",
    "        diagnosis_labels = np.array(diagnosis_labels).reshape(-1, 1)  # Ensure 2D shape\n",
    "        \n",
    "        return (images, clinical_features), diagnosis_labels\n",
    "    \n",
    "    def _augment_image(self, img: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Apply data augmentation while maintaining shape consistency\"\"\"\n",
    "        # Random horizontal flip\n",
    "        if Config.AUGMENTATION_PARAMS['flip'] and np.random.rand() > 0.5:\n",
    "            img = np.fliplr(img)\n",
    "        \n",
    "        # Random rotation\n",
    "        if Config.AUGMENTATION_PARAMS['rotation'] > 0 and np.random.rand() > 0.5:\n",
    "            angle = np.random.uniform(-Config.AUGMENTATION_PARAMS['rotation'] * 180, \n",
    "                                     Config.AUGMENTATION_PARAMS['rotation'] * 180)\n",
    "            rows, cols = img.shape[:2]\n",
    "            M = cv2.getRotationMatrix2D((cols/2, rows/2), angle, 1)\n",
    "            img = cv2.warpAffine(img, M, (cols, rows), borderMode=cv2.BORDER_REFLECT)\n",
    "        \n",
    "        # Random zoom with safe resizing\n",
    "        if Config.AUGMENTATION_PARAMS['zoom'] > 0 and np.random.rand() > 0.5:\n",
    "            zoom_factor = 1 + np.random.uniform(-Config.AUGMENTATION_PARAMS['zoom'], \n",
    "                                               Config.AUGMENTATION_PARAMS['zoom'])\n",
    "            h, w = img.shape[:2]\n",
    "            new_h, new_w = int(h * zoom_factor), int(w * zoom_factor)\n",
    "            img = cv2.resize(img, (new_w, new_h))\n",
    "            # Resize back to original dimensions\n",
    "            img = cv2.resize(img, (w, h))\n",
    "        \n",
    "        # Random contrast\n",
    "        if Config.AUGMENTATION_PARAMS['contrast'] and np.random.rand() > 0.5:\n",
    "            alpha = np.random.uniform(Config.AUGMENTATION_PARAMS['contrast'][0],\n",
    "                                     Config.AUGMENTATION_PARAMS['contrast'][1])\n",
    "            img = np.clip(alpha * img, 0, 1)\n",
    "        \n",
    "        # Random brightness\n",
    "        if Config.AUGMENTATION_PARAMS['brightness'] > 0 and np.random.rand() > 0.5:\n",
    "            beta = np.random.uniform(-Config.AUGMENTATION_PARAMS['brightness'],\n",
    "                                    Config.AUGMENTATION_PARAMS['brightness'])\n",
    "            img = np.clip(img + beta, 0, 1)\n",
    "        \n",
    "        return img\n",
    "    \n",
    "    def _load_and_preprocess(self, file_path: str) -> np.ndarray:\n",
    "        \"\"\"Load and preprocess image with shape validation\"\"\"\n",
    "        img = cv2.imread(file_path)\n",
    "        if img is None:\n",
    "            print(f\"Warning: Could not load image {file_path}. Using zeros.\")\n",
    "            img = np.zeros((*Config.IMAGE_SIZE, 3), dtype=np.uint8)\n",
    "        else:\n",
    "            img = cv2.resize(img, Config.IMAGE_SIZE)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Convert to float and normalize\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        \n",
    "        if self.augment:\n",
    "            img = self._augment_image(img)\n",
    "            \n",
    "        # Ensure consistent shape\n",
    "        if img.shape != (*Config.IMAGE_SIZE, 3):\n",
    "            # Force correct shape\n",
    "            img = cv2.resize(img, Config.IMAGE_SIZE)\n",
    "            if len(img.shape) == 2:\n",
    "                img = np.stack([img, img, img], axis=-1)\n",
    "            elif img.shape[2] > 3:\n",
    "                img = img[:, :, :3]\n",
    "            elif img.shape[2] == 1:\n",
    "                img = np.stack([img.squeeze()]*3, axis=-1)\n",
    "                \n",
    "        return img\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "    \n",
    "    def get_class_distribution(self):\n",
    "        counts = {class_name: 0 for class_name in self.classes}\n",
    "        for _, label in self.file_paths:\n",
    "            class_name = self.class_encoder.inverse_transform([label])[0]\n",
    "            counts[class_name] += 1\n",
    "        return counts\n",
    "    \n",
    "    def get_diagnosis_labels(self):\n",
    "        return [label for _, label in self.file_paths]\n",
    "\n",
    "# Enhanced Model Architecture (Single Output)\n",
    "def build_glaucomanet(trainable_base: bool = False) -> tf.keras.Model:\n",
    "    # Image augmentation layers\n",
    "    augmentation = tf.keras.Sequential([\n",
    "        RandomFlip(\"horizontal\"),\n",
    "        RandomRotation(Config.AUGMENTATION_PARAMS['rotation']),\n",
    "        RandomZoom(Config.AUGMENTATION_PARAMS['zoom']),\n",
    "        RandomContrast(Config.AUGMENTATION_PARAMS['brightness']),\n",
    "    ], name='augmentation')\n",
    "    \n",
    "    # Image input pipeline\n",
    "    img_input = Input(shape=(*Config.IMAGE_SIZE, 3), name='image_input')\n",
    "    augmented = augmentation(img_input)\n",
    "    \n",
    "    # Base model\n",
    "    base_model = tf.keras.applications.MobileNetV2(\n",
    "        include_top=False, \n",
    "        weights='imagenet', \n",
    "        input_tensor=augmented\n",
    "    )\n",
    "    base_model.trainable = trainable_base\n",
    "    x_img = GlobalAveragePooling2D()(base_model.output)\n",
    "    \n",
    "    # Clinical features input\n",
    "    clinical_input = Input(shape=(Config.FEATURE_LENGTH,), name='clinical_input')\n",
    "    \n",
    "    # Feature fusion\n",
    "    fused_features = Concatenate()([x_img, clinical_input])\n",
    "    \n",
    "    # Classification head with regularization\n",
    "    x = Dense(128, activation='relu', \n",
    "              kernel_regularizer=regularizers.l2(Config.REGULARIZATION_L2))(fused_features)\n",
    "    x = Dropout(Config.DROPOUT_RATE)(x)\n",
    "    \n",
    "    # Single output for diagnosis\n",
    "    diagnosis_output = Dense(1, activation='sigmoid', name='diagnosis')(x)\n",
    "    \n",
    "    return Model(\n",
    "        inputs=[img_input, clinical_input],\n",
    "        outputs=diagnosis_output\n",
    "    ), base_model\n",
    "\n",
    "# Learning rate scheduler\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning rate schedule with warmup and decay\"\"\"\n",
    "    warmup_epochs = 3\n",
    "    initial_lr = 1e-4\n",
    "    decay_factor = 0.1\n",
    "    \n",
    "    if epoch < warmup_epochs:\n",
    "        return initial_lr * (epoch + 1) / warmup_epochs\n",
    "    elif epoch < Config.INITIAL_EPOCHS:\n",
    "        return initial_lr\n",
    "    else:\n",
    "        return initial_lr * (decay_factor ** ((epoch - Config.INITIAL_EPOCHS) // 4))\n",
    "\n",
    "# Training and Evaluation\n",
    "class GlaucomaTrainer:\n",
    "    def __init__(self):\n",
    "        self.analyzer = OpticDiscAnalyzer()\n",
    "        self.model, self.base_model = build_glaucomanet(trainable_base=False)\n",
    "        self.output_dir = Config.OUTPUT_DIR\n",
    "        \n",
    "    def get_data_generators(self):\n",
    "        train_gen = GlaucomaDataGenerator(\n",
    "            os.path.join(Config.DATA_DIR, 'train'), \n",
    "            self.analyzer,\n",
    "            augment=True\n",
    "        )\n",
    "        val_gen = GlaucomaDataGenerator(\n",
    "            os.path.join(Config.DATA_DIR, 'validate'), \n",
    "            self.analyzer, \n",
    "            shuffle=False\n",
    "        )\n",
    "        test_gen = GlaucomaDataGenerator(\n",
    "            os.path.join(Config.DATA_DIR, 'test'), \n",
    "            self.analyzer, \n",
    "            shuffle=False\n",
    "        )\n",
    "        return train_gen, val_gen, test_gen\n",
    "    \n",
    "    def compute_class_weights(self, train_gen):\n",
    "        y_train = train_gen.get_diagnosis_labels()\n",
    "        unique_classes = np.unique(y_train)\n",
    "        if len(unique_classes) < 2:\n",
    "            print(\"Warning: Only one class present in training data\")\n",
    "            return {0: 1.0, 1: 1.0}\n",
    "            \n",
    "        class_weights = compute_class_weight('balanced', classes=unique_classes, y=y_train)\n",
    "        return {i: weight for i, weight in enumerate(class_weights)}\n",
    "    \n",
    "    def plot_class_distribution(self, train_gen, val_gen, test_gen):\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "        \n",
    "        train_dist = train_gen.get_class_distribution()\n",
    "        axes[0].bar(train_dist.keys(), train_dist.values())\n",
    "        axes[0].set_title('Train Distribution')\n",
    "        axes[0].set_ylabel('Count')\n",
    "        \n",
    "        val_dist = val_gen.get_class_distribution()\n",
    "        axes[1].bar(val_dist.keys(), val_dist.values())\n",
    "        axes[1].set_title('Validation Distribution')\n",
    "        \n",
    "        test_dist = test_gen.get_class_distribution()\n",
    "        axes[2].bar(test_dist.keys(), test_dist.values())\n",
    "        axes[2].set_title('Test Distribution')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        output_path = os.path.join(self.output_dir, 'class_distribution.png')\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()\n",
    "    \n",
    "    def plot_feature_distribution(self, gen, name):\n",
    "        features = []\n",
    "        for i in range(len(gen)):\n",
    "            (_, clinical), _ = gen[i]\n",
    "            features.append(clinical)\n",
    "            \n",
    "        features = np.vstack(features)\n",
    "        df = pd.DataFrame(features, columns=Config.CLINICAL_FEATURES)\n",
    "        \n",
    "        plt.figure(figsize=(15, 10))\n",
    "        df.boxplot()\n",
    "        plt.title(f'Clinical Feature Distributions - {name}')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        output_path = os.path.join(self.output_dir, f'feature_distribution_{name}.png')\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()\n",
    "        \n",
    "        plt.figure(figsize=(12, 10))\n",
    "        sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
    "        plt.title(f'Feature Correlation Matrix - {name}')\n",
    "        plt.tight_layout()\n",
    "        output_path = os.path.join(self.output_dir, f'feature_correlation_{name}.png')\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()\n",
    "    \n",
    "    def train(self):\n",
    "        train_gen, val_gen, _ = self.get_data_generators()\n",
    "        \n",
    "        self.plot_class_distribution(train_gen, val_gen, val_gen)\n",
    "        self.plot_feature_distribution(train_gen, 'train')\n",
    "        self.plot_feature_distribution(val_gen, 'validation')\n",
    "        \n",
    "        # Compute class weights for imbalanced data\n",
    "        class_weights = self.compute_class_weights(train_gen)\n",
    "        print(f\"Class weights: {class_weights}\")\n",
    "        \n",
    "        # Phase 1: Train the head\n",
    "        print(\"\\n=== Phase 1: Training head ===\")\n",
    "        self.model.compile(\n",
    "            optimizer=Adam(1e-4),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    "        )\n",
    "        \n",
    "        callbacks = [\n",
    "            EarlyStopping(\n",
    "                monitor='val_auc',\n",
    "                patience=5,\n",
    "                restore_best_weights=True,\n",
    "                mode='max',\n",
    "                verbose=1\n",
    "            ),\n",
    "            ModelCheckpoint(\n",
    "                os.path.join(self.output_dir, 'best_model_phase1.weights.h5'),\n",
    "                save_best_only=True,\n",
    "                monitor='val_auc',\n",
    "                mode='max',\n",
    "                save_weights_only=True\n",
    "            ),\n",
    "            ReduceLROnPlateau(\n",
    "                monitor='val_auc',\n",
    "                factor=0.5,\n",
    "                patience=2,\n",
    "                min_lr=1e-6,\n",
    "                mode='max',\n",
    "                verbose=1\n",
    "            ),\n",
    "            LearningRateScheduler(lr_schedule)\n",
    "        ]\n",
    "        \n",
    "        history_phase1 = self.model.fit(\n",
    "            train_gen,\n",
    "            validation_data=val_gen,\n",
    "            epochs=Config.INITIAL_EPOCHS,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1,\n",
    "            class_weight=class_weights\n",
    "        )\n",
    "        \n",
    "        # Phase 2: Fine-tuning\n",
    "        print(\"\\n=== Phase 2: Fine-tuning ===\")\n",
    "        self.base_model.trainable = True\n",
    "        \n",
    "        # Freeze layers before FINE_TUNE_AT\n",
    "        for layer in self.base_model.layers[:Config.FINE_TUNE_AT]:\n",
    "            layer.trainable = False\n",
    "            \n",
    "        print(f\"Number of trainable layers: {sum([1 for layer in self.base_model.layers if layer.trainable])}\")\n",
    "        \n",
    "        self.model.compile(\n",
    "            optimizer=Adam(1e-5),  # Lower learning rate\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    "        )\n",
    "        \n",
    "        callbacks_fine = [\n",
    "            EarlyStopping(\n",
    "                monitor='val_auc',\n",
    "                patience=5,\n",
    "                restore_best_weights=True,\n",
    "                mode='max',\n",
    "                verbose=1\n",
    "            ),\n",
    "            ModelCheckpoint(\n",
    "                os.path.join(self.output_dir, 'best_model_final.weights.h5'),\n",
    "                save_best_only=True,\n",
    "                monitor='val_auc',\n",
    "                mode='max',\n",
    "                save_weights_only=True\n",
    "            ),\n",
    "            ReduceLROnPlateau(\n",
    "                monitor='val_auc',\n",
    "                factor=0.5,\n",
    "                patience=2,\n",
    "                min_lr=1e-7,\n",
    "                mode='max',\n",
    "                verbose=1\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        history_fine = self.model.fit(\n",
    "            train_gen,\n",
    "            validation_data=val_gen,\n",
    "            epochs=Config.INITIAL_EPOCHS + Config.FINE_TUNE_EPOCHS,\n",
    "            initial_epoch=history_phase1.epoch[-1] + 1,\n",
    "            callbacks=callbacks_fine,\n",
    "            verbose=1,\n",
    "            class_weight=class_weights\n",
    "        )\n",
    "        \n",
    "        # Combine histories\n",
    "        history = {\n",
    "            'accuracy': history_phase1.history['accuracy'] + history_fine.history['accuracy'],\n",
    "            'val_accuracy': history_phase1.history['val_accuracy'] + history_fine.history['val_accuracy'],\n",
    "            'auc': history_phase1.history['auc'] + history_fine.history['auc'],\n",
    "            'val_auc': history_phase1.history['val_auc'] + history_fine.history['val_auc'],\n",
    "            'loss': history_phase1.history['loss'] + history_fine.history['loss'],\n",
    "            'val_loss': history_phase1.history['val_loss'] + history_fine.history['val_loss']\n",
    "        }\n",
    "        \n",
    "        self.plot_training_history(history)\n",
    "        return history\n",
    "    \n",
    "    def plot_training_history(self, history):\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        \n",
    "        plt.subplot(2, 2, 1)\n",
    "        plt.plot(history['accuracy'], label='Train')\n",
    "        plt.plot(history['val_accuracy'], label='Validation')\n",
    "        plt.title('Diagnosis Accuracy')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.plot(history['auc'], label='Train')\n",
    "        plt.plot(history['val_auc'], label='Validation')\n",
    "        plt.title('Diagnosis AUC')\n",
    "        plt.ylabel('AUC')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.subplot(2, 2, 3)\n",
    "        plt.plot(history['loss'], label='Train')\n",
    "        plt.plot(history['val_loss'], label='Validation')\n",
    "        plt.title('Loss')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        output_path = os.path.join(self.output_dir, 'training_history.png')\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()\n",
    "    \n",
    "    def evaluate(self):\n",
    "        _, _, test_gen = self.get_data_generators()\n",
    "        \n",
    "        print(\"\\nEvaluating model...\")\n",
    "        test_dist = test_gen.get_class_distribution()\n",
    "        print(\"Test set class distribution:\", test_dist)\n",
    "        \n",
    "        # Load best weights\n",
    "        self.model.load_weights(os.path.join(self.output_dir, 'best_model_final.weights.h5'))\n",
    "        \n",
    "        results = self.model.evaluate(test_gen, verbose=0)\n",
    "        print(\"\\nTest Results:\")\n",
    "        print(f\"Loss: {results[0]:.4f}\")\n",
    "        print(f\"Accuracy: {results[1]:.4f}\")\n",
    "        print(f\"AUC: {results[2]:.4f}\")\n",
    "        \n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        \n",
    "        for i in range(len(test_gen)):\n",
    "            (images, clinical), labels = test_gen[i]\n",
    "            batch_pred = self.model.predict([images, clinical], verbose=0)\n",
    "            y_true.extend(labels.flatten().tolist())\n",
    "            y_pred.extend(batch_pred.flatten().tolist())\n",
    "        \n",
    "        y_true = np.array(y_true)\n",
    "        y_pred = np.array(y_pred)\n",
    "        \n",
    "        # Convert labels to 0 and 1\n",
    "        unique_vals = np.unique(y_true)\n",
    "        print(f\"Unique values in y_true: {unique_vals}\")\n",
    "        \n",
    "        if set(unique_vals) == {1, 2}:\n",
    "            print(\"Adjusting labels: subtracting 1\")\n",
    "            y_true = y_true - 1\n",
    "        elif set(unique_vals) == {0, 1}:\n",
    "            print(\"Labels are 0 and 1, no adjustment needed\")\n",
    "        else:\n",
    "            print(\"Unexpected label values. Converting to binary:\")\n",
    "            y_true = (y_true != np.min(y_true)).astype(int)\n",
    "        \n",
    "        print(f\"Adjusted unique values: {np.unique(y_true)}\")\n",
    "        \n",
    "        # Save classification report\n",
    "        report = classification_report(y_true, y_pred > 0.5, target_names=['Normal', 'Glaucoma'])\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(report)\n",
    "        \n",
    "        # Save report to file\n",
    "        report_path = os.path.join(self.output_dir, 'classification_report.txt')\n",
    "        with open(report_path, 'w') as f:\n",
    "            f.write(\"Classification Report:\\n\")\n",
    "            f.write(report)\n",
    "            f.write(f\"\\nTest Loss: {results[0]:.4f}\")\n",
    "            f.write(f\"\\nTest Accuracy: {results[1]:.4f}\")\n",
    "            f.write(f\"\\nTest AUC: {results[2]:.4f}\")\n",
    "        \n",
    "        # Confusion matrix\n",
    "        cm = confusion_matrix(y_true, y_pred > 0.5)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                   xticklabels=['Normal', 'Glaucoma'],\n",
    "                   yticklabels=['Normal', 'Glaucoma'])\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.tight_layout()\n",
    "        output_path = os.path.join(self.output_dir, 'confusion_matrix.png')\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()\n",
    "        \n",
    "        # ROC curve\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "        roc_auc = roc_auc_score(y_true, y_pred)\n",
    "        \n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, \n",
    "                label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.tight_layout()\n",
    "        output_path = os.path.join(self.output_dir, 'roc_curve.png')\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()\n",
    "        \n",
    "        self.analyze_feature_importance(test_gen)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def analyze_feature_importance(self, test_gen):\n",
    "        \"\"\"Analyze clinical feature importance using permutation on entire test set\"\"\"\n",
    "        print(\"\\nAnalyzing feature importance...\")\n",
    "        \n",
    "        # Collect entire test set\n",
    "        all_images = []\n",
    "        all_clinical = []\n",
    "        all_diagnosis = []\n",
    "        \n",
    "        for i in range(len(test_gen)):\n",
    "            (images, clinical), diagnosis = test_gen[i]\n",
    "            all_images.append(images)\n",
    "            all_clinical.append(clinical)\n",
    "            all_diagnosis.append(diagnosis)\n",
    "        \n",
    "        all_images = np.vstack(all_images)\n",
    "        all_clinical = np.vstack(all_clinical)\n",
    "        all_diagnosis = np.vstack(all_diagnosis)\n",
    "        \n",
    "        # Convert labels to 0 and 1\n",
    "        unique_vals = np.unique(all_diagnosis)\n",
    "        if set(unique_vals) == {1, 2}:\n",
    "            all_diagnosis = all_diagnosis - 1\n",
    "        elif set(unique_vals) == {0, 1}:\n",
    "            pass\n",
    "        else:\n",
    "            all_diagnosis = (all_diagnosis != np.min(all_diagnosis)).astype(int)\n",
    "        \n",
    "        # Baseline prediction\n",
    "        baseline_pred = self.model.predict([all_images, all_clinical])\n",
    "        baseline_auc = roc_auc_score(all_diagnosis, baseline_pred)\n",
    "        print(f\"Baseline AUC: {baseline_auc:.4f}\")\n",
    "        \n",
    "        feature_importance = []\n",
    "        for i, feature_name in enumerate(Config.CLINICAL_FEATURES):\n",
    "            print(f\"Processing feature {i+1}/{len(Config.CLINICAL_FEATURES)}: {feature_name}\")\n",
    "            \n",
    "            clinical_permuted = all_clinical.copy()\n",
    "            np.random.shuffle(clinical_permuted[:, i])\n",
    "            \n",
    "            permuted_pred = self.model.predict([all_images, clinical_permuted])\n",
    "            permuted_auc = roc_auc_score(all_diagnosis, permuted_pred)\n",
    "            \n",
    "            importance = baseline_auc - permuted_auc\n",
    "            feature_importance.append(importance)\n",
    "            print(f\"  Feature importance: {importance:.4f}\")\n",
    "        \n",
    "        # Save feature importance to file\n",
    "        importance_path = os.path.join(self.output_dir, 'feature_importance.txt')\n",
    "        with open(importance_path, 'w') as f:\n",
    "            f.write(\"Feature Importance (Permutation Test):\\n\")\n",
    "            for name, imp in zip(Config.CLINICAL_FEATURES, feature_importance):\n",
    "                f.write(f\"{name}: {imp:.6f}\\n\")\n",
    "        \n",
    "        # Plot feature importance\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.barh(Config.CLINICAL_FEATURES, feature_importance)\n",
    "        plt.title('Clinical Feature Importance (Permutation Test)')\n",
    "        plt.xlabel('AUC Decrease')\n",
    "        plt.tight_layout()\n",
    "        output_path = os.path.join(self.output_dir, 'feature_importance.png')\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting Robust Glaucoma Detection System...\")\n",
    "    print(f\"All outputs will be saved to: {Config.OUTPUT_DIR}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        trainer = GlaucomaTrainer()\n",
    "        history = trainer.train()\n",
    "        results = trainer.evaluate()\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"\\nExecution completed successfully in {elapsed/60:.2f} minutes!\")\n",
    "        print(f\"All outputs saved to: {Config.OUTPUT_DIR}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nCritical error encountered: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        print(\"\\nSystem terminated due to error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf0e03b-3097-47a0-a7e0-eeaca7100fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d062a3-7d5f-4dfb-8a97-6a46ef84b422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1d9146-8ac5-4926-be30-1591bc15c139",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
